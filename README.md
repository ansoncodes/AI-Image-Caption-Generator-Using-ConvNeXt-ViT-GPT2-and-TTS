# ğŸ§  AI Image Caption Generator

This project uses a Vision Transformer-based deep learning model to generate descriptive captions for uploaded images. The final caption is also converted into spoken audio using built-in Python audio tools, making the system useful for accessibility and assistive technologies.

---

## âœ… What It Does

### ğŸ–¼ï¸ Image Captioning
- Uses the **ViT-GPT2 model** (`VisionEncoderDecoderModel`) from [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- Images are preprocessed using `ViTFeatureExtractor`
- The model outputs descriptive captions like:  
  > *"a cat sitting on a couch"*

### ğŸ”Š Audio Playback
- Captions are converted to **speech audio (.wav)** using built-in audio recording methods (not Glow-TTS)
- The audio is played directly within the notebook using `IPython.display.Audio`

### ğŸ›ï¸ Interactive Interface
- Created with `ipywidgets` for user-friendly image uploads
- Automatically displays:
  - Uploaded image
  - Generated caption
  - Audio playback of the caption

---

## ğŸ“‚ File Overview

```
â”œâ”€â”€ AI_Image_Caption_Generator.ipynb   # Main notebook
â”œâ”€â”€ README.md                          # This file
```

---

## ğŸ§  Technologies Used

| Purpose              | Library/Tool |
|----------------------|--------------|
| Model Architecture   | ViT-GPT2 (`VisionEncoderDecoderModel`) |
| Image Processing     | `ViTFeatureExtractor` |
| Audio Playback       | `IPython.display.Audio` |
| Interactive Upload   | `ipywidgets.FileUpload`, `widgets.Image`, etc. |
| Language             | Python |
| Platform             | Jupyter Notebook |

---

## ğŸš€ How to Run

1. **Install dependencies**:

```bash
pip install torch torchvision transformers pillow ipywidgets
```

2. **Start the notebook**:

```bash
jupyter notebook AI_Image_Caption_Generator.ipynb
```

3. **Upload an image** using the widget  
   â†’ View the caption  
   â†’ Hear the audio narration

---

## ğŸ¯ Use Cases

- ğŸ§‘â€ğŸ¦¯ **Accessibility**: Describes images for visually impaired users
- ğŸ§‘â€ğŸ« **Education**: Helps children or non-readers understand image content
- ğŸ“¸ **Narrative content**: Adds spoken descriptions to photos

---

## ğŸ“ Notes

- An earlier **ConvNeXt model** is included in the notebook but is not used in the final captioning pipeline.
- No external TTS (e.g., Glow-TTS) library is currently used.
- Audio is generated using native Python tools, not deep learning-based synthesis.

---

## ğŸ“ƒ License

This project is for educational and academic use only.
